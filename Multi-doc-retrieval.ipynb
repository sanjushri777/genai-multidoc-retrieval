{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331702e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c87df8a1",
   "metadata": {
    "height": 897
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading,wait\n",
      "Loading,wait\n",
      "Loading,wait\n",
      "Available documents are:\n",
      "knowledge_card.pdf\n",
      "swebench.pdf\n",
      "longlora.pdf\n",
      "Ask your query related to these documents: \n",
      "summarize all documents\n",
      "Response: \n",
      "\n",
      "assistant: The documents mentioned cover a wide range of topics related to natural language processing, machine learning, software engineering, code generation, program repair, transformers, and neural networks. They discuss various innovative approaches, techniques, and experiments in the field, including the integration of external knowledge sources with large language models, benchmarking neural code generation, program synthesis, automated program repair, and efficient fine-tuning in large language models. The experiments involve evaluating model performance on different datasets and exploring attention patterns for fine-tuning pre-trained models. The documents provide detailed insights into evaluation processes, metrics calculation, test set characterization, repository statistics, issue categories, patch fix rates, and training details for various tasks and instances.\n"
     ]
    }
   ],
   "source": [
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# List of papers to load\n",
    "papers = [\n",
    "    \"knowledge_card.pdf\",\n",
    "    \"swebench.pdf\",\n",
    "    \"longlora.pdf\"\n",
    "]\n",
    "\n",
    "# Loading vector tools and summary tools for each paper\n",
    "from utils import get_doc_tools\n",
    "from pathlib import Path\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(\"Loading,wait\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
    "\n",
    "initial_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]\n",
    "\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    initial_tools, \n",
    "    llm=llm, \n",
    "    verbose=False\n",
    ")\n",
    "agent = AgentRunner(agent_worker)\n",
    "\n",
    "\n",
    "print(\"Available documents are:\")\n",
    "for p in papers:\n",
    "    print(p)\n",
    "\n",
    "\n",
    "question = input(\"Ask your query related to these documents: \\n\")\n",
    "\n",
    "response = agent.query(question) \n",
    "\n",
    "print(\"Response: \\n\")\n",
    "print(response) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
